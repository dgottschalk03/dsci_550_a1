{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.03 Date Feature Extraction**\n",
    "\n",
    "## **Date Extraction**\n",
    "\n",
    "Date extacted using [datefinder](https://github.com/akoumjian/datefinder)\n",
    " \n",
    "**\"Haunted Places Date\" [datetime]**\n",
    "- Format: YYYY/MM/DD\n",
    "- Default Value: 2015/01/01\n",
    "\n",
    "**NOTES**:\n",
    "\n",
    "- datefinder.find_dates() will parse any number as an incomplete date and set the year to 2025. \n",
    "    - To filter out false positives, we filter out dates with year == 2025. \n",
    "- Used Regex Expression to capture \"20's, 30's, etc.\". \n",
    "    - eg {index: 1275}: *\"A little boy haunts theater number 5 who was killed back in the '70's during a freak construction accident.* -> [datetime.datetime(1970, 1, 1, 0, 0)]\n",
    "- Regex Pattern for 4 digits includes \"In the\". This avoids false positives:\n",
    "    - eg. {index: 1167}: \"A young man dressed **in 1700's clothing** has been seen through the windows of the first floor. He also bangs on windows late at night as if trying to escape. It is believed that the body of the young soldier is buried on the grounds of Craven Hall.\"\n",
    "- Before extract_dates output, we removed all dates < 1620 (landing at Plymouth Rock). \n",
    "    - eg. {index: 3} = \"In the 1970's, one room, **room 211** ...\" -> datetime([211, 1, 1]).\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datefinder\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Reading CSV\n",
    "df = pd.read_csv(\"../data/processed/haunted_places_cleaned.tab\", sep = \"\\t\")\n",
    "df[\"description\"] = df[\"description\"].fillna(\" \").astype(str)\n",
    "\n",
    "\n",
    "\n",
    "def extract_dates(text):\n",
    "    \"\"\"\n",
    "    Extract dates from a given text using three different methods:\n",
    "    - `datefinder`\n",
    "    - Two-digit regex patterns (e.g., \"20's\", \"30s\")\n",
    "    - Four-digit regex patterns (e.g., \"1920s\", \"1970's\")\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text containing potential date references.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "            - dates (list of datetime): Extracted date objects.\n",
    "            - datefinder_count (int): Number of dates found using datefinder.\n",
    "            - two_digit_pattern_count (int): Number of dates found using two-digit patterns.\n",
    "            - four_digit_pattern_count (int): Number of dates found using four-digit patterns.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Parse Using DateFinder ##\n",
    "    # Remove Years < 1620 #\n",
    "    matched_dates = [date for date in datefinder.find_dates(text, base_date = datetime.datetime(2025, 1, 1)) \n",
    "                    if isinstance(date, datetime.datetime) and 1620 <= date.year < 2026]\n",
    "    datefinder_count = len(matched_dates)\n",
    "\n",
    "\n",
    "    matched_years = []\n",
    "\n",
    "    ## Parse Two Digit Pattern eg. \"20's\" ##\n",
    "    two_digit_pattern = [r\"\\b\\d{2}'s\\b\", r\"\\b\\d{2}s\\b\", r\"\\bin the \\d{2}'s\\b\", r\"\\bin the \\d{2}s\\b\"]\n",
    "    for pattern in two_digit_pattern:\n",
    "        matched_years.extend(\n",
    "            [re.sub(r\"in the|'|s\", \"\", year.lower()).strip() for year in re.findall(pattern, text, re.IGNORECASE)]\n",
    "        )\n",
    "    matched_years = [\"19\" + year for year in matched_years]\n",
    "    two_digit_pattern_count = len(matched_years)\n",
    "\n",
    "    ## Parse 4 Digit Pattern eg. \"in the 1970's\" ##\n",
    "    four_digit_pattern = [r\"\\bin the \\d{4}'s\\b\", r\"\\bin the \\d{4}s\\b\"]\n",
    "    for pattern in four_digit_pattern:\n",
    "        matched_years.extend(\n",
    "            [re.sub(r\"in the|'|s\", \"\", year.lower()).strip() for year in re.findall(pattern, text, re.IGNORECASE)]\n",
    "        )\n",
    "    four_digit_pattern_count = len(matched_years) - two_digit_pattern_count\n",
    "\n",
    "    ## Add Regex to Matched_Dates **\n",
    "    for year in matched_years:\n",
    "        matched_dates.append(datetime.datetime(int(year), 1, 1)) \n",
    "\n",
    "    ## If No Dates Matched, Return [2025, 1, 1] ##\n",
    "    if matched_dates == []:\n",
    "        matched_dates.append(datetime.datetime(2025, 1, 1))\n",
    "\n",
    "    ## Remove Duplicates ##\n",
    "    matched_dates = list(set(matched_dates))\n",
    "    \n",
    "    res = {\n",
    "        \"dates\" : matched_dates,\n",
    "        \"datefinder_count\" : datefinder_count,\n",
    "        \"two_digit_pattern_count\" : two_digit_pattern_count,\n",
    "        \"four_digit_pattern_count\" : four_digit_pattern_count  \n",
    "    }\n",
    "\n",
    "    return res\n",
    "\n",
    "start = time.time()\n",
    "df[\"Haunted_Places_Date\"] = df[\"description\"].apply(extract_dates)\n",
    "end = time.time()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract Counts From Each Method ##\n",
    "df[\"Datefinder_Extracts\"] = df[\"Haunted_Places_Date\"].apply(lambda x: x[\"datefinder_count\"])\n",
    "df[\"Two_Digit_Extracts\"] = df[\"Haunted_Places_Date\"].apply(lambda x: x[\"two_digit_pattern_count\"])\n",
    "df[\"Four_Digit_Extracts\"] = df[\"Haunted_Places_Date\"].apply(lambda x: x[\"four_digit_pattern_count\"])\n",
    "\n",
    "\n",
    "date_finder_total = df[\"Datefinder_Extracts\"].sum()\n",
    "two_digit_total = df[\"Two_Digit_Extracts\"].sum()\n",
    "four_digit_total = df[\"Four_Digit_Extracts\"].sum()\n",
    "\n",
    "extract_printout = [(\"Datefinder\", date_finder_total), \n",
    "                    (\"Two_Digit\", two_digit_total), \n",
    "                    (\"Four_Digit\",four_digit_total), \n",
    "                    (\"Total\", date_finder_total + two_digit_total + four_digit_total)]\n",
    "\n",
    "## Overwrite Date Column To Exclude Counts ##\n",
    "df[\"Haunted_Places_Date\"] = df[\"Haunted_Places_Date\"].apply(lambda x: x[\"dates\"])\n",
    "\n",
    "## Find Multi Date Entries ##\n",
    "multi_date_idx = df[\"Haunted_Places_Date\"].apply(lambda x : len(x) > 2 if isinstance(x, list) else False)\n",
    "multi_date_entries = df[multi_date_idx == True]\n",
    "\n",
    "## Expand DataFrame ##\n",
    "exploded_df = df.explode(\"Haunted_Places_Date\")\n",
    "## Take Dates Out of List ##\n",
    "exploded_df['Haunted_Places_Date'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "## Convert to Datetime. Fillna with [2025, 1, 1] ##\n",
    "exploded_df[\"Haunted_Places_Date\"] = pd.to_datetime(exploded_df[\"Haunted_Places_Date\"], errors=\"coerce\").fillna(datetime.datetime(2025, 1, 1))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['description'].str.contains('thirties', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Haunted_Places_Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Haunted_Places_Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m9520\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHaunted_Places_Date\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexing.py:1183\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:4214\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4211\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[0;32m-> 4214\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(col)\n\u001b[1;32m   4215\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4218\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4219\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4220\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/frame.py:4638\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4633\u001b[0m res \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(item)\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4635\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[0;32m-> 4638\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(item)\n\u001b[1;32m   4639\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4641\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Haunted_Places_Date'"
     ]
    }
   ],
   "source": [
    "df.loc[9520, \"Haunted_Places_Date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------------------------------------ Extraction Completed ------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Extraction Took: 9.535893 seconds\n",
      "\n",
      "Datefinder: 5817 dates extracted\n",
      "Two_Digit: 94 dates extracted\n",
      "Four_Digit: 0 dates extracted\n",
      "Total: 5911 dates extracted\n",
      "multi-date entries: 421\n",
      "\n",
      "Old Dataframe Shape: (10992, 14) -> New DataFrame Shape: (12871, 14)\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Printout Report ##\n",
    "print(\"-\" * 150, \"Extraction Completed\", \"-\" * 150)\n",
    "print(f\"Extraction Took: {end - start:.6f} seconds\", end = \"\\n\\n\")\n",
    "print(\"\\n\".join([f\"{extract_str[0]}: {extract_str[1]} dates extracted\" for extract_str in extract_printout]))\n",
    "print(f\"multi-date entries: {len(multi_date_entries)}\", end = \"\\n\\n\")\n",
    "print(f\"Old Dataframe Shape: {df.shape} -> New DataFrame Shape: {exploded_df.shape}\")\n",
    "print(\"-\" * 150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

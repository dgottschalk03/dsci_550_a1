{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data PreProcessing**\n",
    "Preprocessing data before extracting haunted features. \n",
    "\n",
    "Descriptions Parsed using [tika](https://github.com/chrismattmann/tika-python) and [org.apache.tika.parser.DefaultParser]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Clean Stop Words and Punctuation**\n",
    "We found that datefinder and number parser work best when strings are cleaned of stopwords.\n",
    "\n",
    "1. Stopwords cleaned using [natural_language_toolkit_python](https://www.nltk.org/)\n",
    "    - Stopword Set: nltk.corpus.stopwords\n",
    "2. Punctuations removed using python [string_module](https://docs.python.org/3/library/string.html)\n",
    "    - Punctuation Set: {!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~.}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tika as tk\n",
    "from tika import parser\n",
    "import pandas as pd\n",
    "\n",
    "## Extract Text from File ##\n",
    "\n",
    "def extract_text(file):\n",
    "    # Parse the CSV file\n",
    "    parsed_data = tk.parser.from_file(file)\n",
    "\n",
    "    # Extract Text \n",
    "    csv_text = parsed_data[\"content\"]\n",
    "    # Print Metadata\n",
    "    print(parsed_data[\"metadata\"])\n",
    "\n",
    "    return csv_text\n",
    "\n",
    "extracted_text = extract_text(\"../data/raw/haunted_places.tab\")\n",
    "extracted_text_list = extracted_text.split(\"\\t\")\n",
    "\n",
    "## Read DataFrame Using Pandas to Get Column Index ##\n",
    "df = pd.read_csv(\"../data/raw/haunted_places.tab\", delimiter = \"\\t\") \n",
    "headers = df.columns.tolist()\n",
    "column_idx = headers.index(\"description\") + 1\n",
    "num_rows = df.shape[0]\n",
    "\n",
    "## Extract Descriptions from List, Set all Chars to Lowercase ##\n",
    "extracted_descriptions = [extracted_text_list[column_idx + i * len(headers)] for i in range(1,num_rows + 1)]\n",
    "extracted_descriptions = list(map(lambda x : x.lower().strip(), extracted_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dgottschalk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/dgottschalk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/var/folders/_b/bl5yw1q15msg5ky9z_04dpt40000gn/T/ipykernel_58932/2395497059.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_out['longitude'].fillna(df_out['city_longitude'], inplace = True)\n",
      "/var/folders/_b/bl5yw1q15msg5ky9z_04dpt40000gn/T/ipykernel_58932/2395497059.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_out['latitude'].fillna(df_out['city_latitude'], inplace = True)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "## Download StopWords and Tokenizer ##\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "## Keep \"I\" and \"We\" for witness feature ##\n",
    "stop_words.discard('i')\n",
    "stop_words.discard('we')\n",
    "# stop_words.discard('me')\n",
    "\n",
    "## init Clean Descriptions ##\n",
    "cleaned_descriptions = []\n",
    "df_out = df.copy()\n",
    "\n",
    "for i in range(len(extracted_descriptions)):\n",
    "    description = extracted_descriptions[i]\n",
    "    \n",
    "    ## Only Add Non-Stopwords and Non-Punctuation Tokens ##\n",
    "    ## Keeping Periods ##\n",
    "    description = \" \".join([word.lower().strip() for word in word_tokenize(description.replace('.', '. ')) if (word not in stop_words) and (word not in string.punctuation.replace('.',''))])\n",
    "\n",
    "    ## Write Cleaned Description To df_out ##\n",
    "    df_out.iloc[i, column_idx - 1] = description\n",
    "\n",
    "\n",
    "## Fill NAN Values ##\n",
    "df_out[\"description\"] = df_out[\"description\"].fillna(\"Invalid_Description\").astype(str)\n",
    "\n",
    "# Fill missing coordinates with city coordinates #\n",
    "df_out['longitude'].fillna(df_out['city_longitude'], inplace = True)\n",
    "df_out['latitude'].fillna(df_out['city_latitude'], inplace = True)\n",
    "\n",
    "\n",
    "# Removing Invalid Descriptions ##\n",
    "df_out.drop(1063, inplace = True)\n",
    "\n",
    "## Saving ##\n",
    "df_out.to_csv(\"../data/processed/haunted_places_cleaned.tab\", index = False, header = True, sep = \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
